{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 4 - 3- Classifying Sign Language Solution",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc8bx8pfcQ96"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from os import getcwd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy55uMK3c0Vo"
      },
      "source": [
        "\n",
        "  # You will need to write code that will read the file passed\n",
        "  # into this function. The first line contains the column headers\n",
        "  # so you should ignore it\n",
        "  # Each successive line contians 785 comma separated values between 0 and 255\n",
        "  # The first value is the label\n",
        "  # The rest are the pixel values for that picture\n",
        "  # The function will return 2 np.array types. One with all the labels\n",
        "  # One with all the images\n",
        "  #\n",
        "  # Tips: \n",
        "  # If you read a full line (as 'row') then row[0] has the label\n",
        "  # and row[1:785] has the 784 pixel values\n",
        "  # Take a look at np.array_split to turn the 784 pixels into 28x28\n",
        "  # You are reading in strings, but need the values to be floats\n",
        "  # Check out np.array().astype for a conversion\n",
        "\n",
        "\n",
        "def get_data(filename):\n",
        "  with open(filename) as training_file:\n",
        "    csv_reader = csv.reader(training_file,delimiter=\",\")\n",
        "\n",
        "      #The next() function returns the next item in an iterator : skipping 1st line\n",
        "\n",
        "    next(csv_reader,None)\n",
        "\n",
        "    labels = []\n",
        "    images = []\n",
        "\n",
        "    for row in csv_reader:\n",
        "      label = row[0]\n",
        "      image_data = row[1:785]\n",
        "      img = np.array(image_data).reshape((28,28))\n",
        "\n",
        "      images.append(img)\n",
        "      labels.append(label)\n",
        "\n",
        "    images = np.array(images).astype(\"float\")\n",
        "    labels = np.array(labels).astype(\"float\")\n",
        "\n",
        "    return labels,images\n",
        "\n",
        "path_sign_mnist_train = f\"{getcwd()}/../tmp2/sign_mnist_train.csv\"\n",
        "path_sign_mnist_test = f\"{getcwd()}/../tmp2/sign_mnist_test.csv\"\n",
        "\n",
        "training_images, training_labels = get_data(path_sign_mnist_train)\n",
        "testing_images, testing_labels = get_data(path_sign_mnist_test)\n",
        "\n",
        "# Keep these\n",
        "print(training_images.shape)\n",
        "print(training_labels.shape)\n",
        "print(testing_images.shape)\n",
        "print(testing_labels.shape)\n",
        "\n",
        "# Their output should be:\n",
        "# (27455, 28, 28)\n",
        "# (27455,)\n",
        "# (7172, 28, 28)\n",
        "# (7172,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UBbswd5lKDc"
      },
      "source": [
        "#Change the dimensions of images using np.expand_dims\n",
        "\n",
        "training_images = np.expand_dims(training_images, axis=3)\n",
        "\n",
        "testing_images = np.expand_dims(testing_images, axis=3)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255)\n",
        "\n",
        "print(training_images.shape)\n",
        "print(testing_images.shape)\n",
        "\n",
        "#Expected Output:\n",
        "(27455, 28, 28, 1)\n",
        "(7172, 28, 28, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFiuIFDyl6Tf"
      },
      "source": [
        "# Define the model\n",
        "# Use no more than 2 Conv2D and 2 MaxPooling2D\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(26, activation=tf.nn.softmax)])\n",
        "\n",
        "# Compile Model. \n",
        "model.compile(optimizer = \"adam\",\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Configure generators\n",
        "train_gen = train_datagen.flow(\n",
        "    training_images,\n",
        "    training_labels,\n",
        "    batch_size=32)\n",
        "\n",
        "val_gen = validation_datagen.flow(\n",
        "    testing_images,\n",
        "    testing_labels,\n",
        "    batch_size=32)\n",
        "\n",
        "# Train the Model\n",
        "history = model.fit_generator(train_gen,\n",
        "                              steps_per_epoch=len(training_images) / 32,\n",
        "                              epochs=15,\n",
        "                              val_gen,\n",
        "                              validation_steps=len(testing_images) / 32)\n",
        "\n",
        "model.evaluate(testing_images, testing_labels)\n",
        "\n",
        "# The output from model.evaluate should be close to:\n",
        "[6.92426086682151, 0.56609035]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu-bUmZJpS0k"
      },
      "source": [
        "# Plot the chart for accuracy and loss on both training and validation\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}